
\graphicspath{ {5chapterImplementation/image/} }
\chapter{Experimental result}
\section{Test image set}
To evaluate our method, we use the publicly accessible benchmark of natural scenes containing text of the ICDAR 2013 competitions. The main set used come from the second challenge: "Focused Scene Text". The test set contains 233 scenes images focused on text on banners, signs or labels in real life, most of them are in the horizontal direction. The ground truth was create manually by observing and painting each character pixels. This operator made the ground-truth of ICDAR 2013 data set more reliable than the ICDAR 2011.   
 
\section{Evaluation Protocols}
In this section, we summarize the protocol for text detection and recognition evaluation used. We used the IDCAR protocol DelEval by Wolf et al \cite{} which is most commonly adopted. DelEval detection protocol supports both one-to-one and on-to-many matches between the ground truth and detection. It also considers over-split and over-merge of detection. The performance of a detection algorithm is illustrated intuitively by performance graphs which present object level precision and recall depending on constraints on detection quality.
\section{Result and comments}