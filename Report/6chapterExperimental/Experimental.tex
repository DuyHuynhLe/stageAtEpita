
\graphicspath{ {6chapterExperimental/image/} }
\chapter{Experimental result}
\section{Test image set}
To evaluate our method, we use the publicly accessible benchmark of natural scenes containing text of the ICDAR 2013 competitions. The main set used come from the second challenge: "Focused Scene Text". The test set contains 233 scenes images focused on text on banners, signs or labels in real life, most of them are in the horizontal direction. The ground truth was create manually by observing and painting each character pixels. This operator made the ground-truth of ICDAR 2013 data set more reliable than the ICDAR 2011.   
 
\section{Evaluation Protocols}
In this section, we summarize the protocol for text detection and recognition evaluation used. We used the IDCAR protocol DelEval by Wolf et al \cite{WolfIJDAR2006} which is most commonly adopted. DelEval detection protocol supports both one-to-one and on-to-many matches between the ground truth and detection as in \ref{fig:GroundTruthMatch}. It also considers over-split and over-merge of detection. The performance of a detection algorithm is illustrated intuitively by performance graphs which present object level precision and recall depending on constraints on detection quality.
\begin{figure}
\begin{center}


	\begin{subfigure}[b]{\textwidth}
	 	\includegraphics[scale=0.5]{oneOne.png} \centering \caption{}\label{fig:oneOne} \end{subfigure}
		
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[scale=0.5]{manyOne.png} \centering	 \caption{}\label{fig:manyOne} \end{subfigure}		 	
	 	
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[scale=0.5]{oneMany.png} \centering	 \caption{}\label{fig:oneMany} \end{subfigure}	


	
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[height = 1cm]{comment.png} \centering	 \caption{}\label{fig:comment} \end{subfigure}
\end{center}
	\caption[Example of ground truth match types] {Different match types between ground truth rectangles and detected rectangles: \ref{fig:oneOne} one-to-one match; \ref{fig:manyOne} a merge: a one-to-many match with one detected rectangle; \ref{fig:oneMany} a split: a one-to-many match with one ground truth rectangle.}
	\label{fig:GroundTruthMatch}
\end{figure}

\section{Result and comments}
\subsection*{Outputs of the algorithm}
Through our process, the input images \ref{fig:inputImage} will be convert into gray level image \ref{fig:grayScale}, then the interpolated laplacian map will be created \ref{fig:Laplacian}. Along with the laplacian map, a gradient map \ref{fig:gradient} will also be calculate for addition information. Through experimental, The element structural used is a 11x11 square for both laplacian and gradient as this size is large enough to ignore small component but does not destroy text structure. Components will be labeled \ref{fig:labeled}. During the labeling process, some attributes, which are precised in section \ref{labeling}, will be checked during the contour following process. Contour of removed component can be seen in \ref{fig:labeling_contour} (red contour). As the laplacian is sensitive to noise so there are numerous component has been introduced, they were mostly removed by thresholding the value obtain by following the outside contour of each component (bounding boxes of components will also be calculated at the same time\ref{fig:BoundingBoxOfCharacter}). When we process the example image \ref{fig:inputImage} from the ICDAR2013 set, 14650 components was removed because they are too small, 12623 components which passed the size threshold are removed by gradient threshold, 102 others components are removed after by the ratio criteria, only 149 components are kept as character candidates. 


\begin{figure}

	\begin{subfigure}[b]{0.45\textwidth}
	 	\includegraphics[width=7cm]{output/img_20.jpg} \caption{Original image}\label{fig:inputImage} \end{subfigure}
	\begin{subfigure}[b]{0.45\textwidth}
	 	\includegraphics[width=7cm]{output/Gau20.png} \caption{Gray level image}\label{fig:grayScale} \end{subfigure}	 	
\centering		
		
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=7cm]{output/lap20.png}  \caption{Morphological Laplacian}\label{fig:Laplacian} \end{subfigure}	
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=7cm]{output/grad20.png}  \caption{Morphological gradient}\label{fig:gradient} \end{subfigure}	
\centering

	\caption[Outputs of the labeling process] {Outputs of the labeling process}
	\label{fig:output}
\end{figure}


Components will grouped into words candidates \ref{fig:BoundingBoxOfWordCandidateOnLabel} using algorithm in section \ref{Grouping}. The bounding box will be scale back to the original resolution (before interpolation) of input image \ref{fig:BoundingBoxOfWordCandidate}.


\begin{figure}

	\begin{subfigure}[t]{0.45\textwidth}
	\captionsetup{width=0.85\textwidth} 
		\includegraphics[width=7cm]{output/lab20TextBorder.png}  \caption{Components labels with their bounding boxes (shown in red)}\label{fig:BoundingBoxOfCharacter} \end{subfigure}	
	\begin{subfigure}[t]{0.45\textwidth} 
	\captionsetup{width=0.80\textwidth} 
	\includegraphics[width=7cm]{output/lab20Cropped.png}  
	\caption{zoom in at the number 88, with contour of components removed shown. Components which do not pass gradient threshold are shown in red, which do not pass size threshold are shown in black and which do not pass ratio threshold are shown in blue}\label{fig:labeling_contour} \end{subfigure}	
\centering	


	\begin{subfigure}[b]{0.45\textwidth}
	\captionsetup{width=0.85\textwidth} 
		\includegraphics[width=7cm]{output/lab20WordLabeled.png}  \caption{Bounding boxes of word candidate shown in green}\label{fig:BoundingBoxOfWordCandidateOnLabel} \end{subfigure}
	\begin{subfigure}[b]{0.45\textwidth}
	\captionsetup{width=0.85\textwidth}
		\includegraphics[width=7cm]{output/20.png}  \caption{Bounding boxes of word candidate on original image}\label{fig:BoundingBoxOfWordCandidate} \end{subfigure}			
\centering	
		
	\caption[Word candidates output] {Word candidates output}
	\label{fig:Wordcandidatesoutput}
\end{figure}
\subsection{Modification of algorithms}
As we remove most of week component introduced by the laplacian, the results shown that high number of false positive remain. We then try to further eliminate the false positive by 2 approaches. First, we use a classic method: blurring out the original image with a small kernel (3 pixels) to reduces noises. Although it destroy the shapes of component and modifies contours, the a small kernel keeps this modification s . We test several combination using the same threshold to find the best one:

\begin{itemize}
\item {\textbf{CP1}} : Laplacian and gradient are calculated from the original gray level image.
\item {\textbf{CP2}} : Laplacian is calculated from the original image and gradient is calculated from the blurred image.
\item {\textbf{CP3}} : Laplacian and gradient are calculated from the blurred image.
\item {\textbf{CP4}} : Laplacian  and gradient is calculated from the original image.
\end{itemize}

Second, we use the laplacian value of each component as additional information to remove components with low contrast. At first, we uses the average of 10\% strongest points of that region as a feature to decide if the zero crossing is strong but the we find out that the peak value of each region is enough. We called the first approach average laplacian and the second one peak laplacian.

\subsection{Experimental}
The bounding box coordinates will be extracted and verified with ground truth provided by ICDAR, using the DetEval protocole by $Wolf et al$ \cite{WolfIJDAR2006}

\begin {table}[H]

\begin{tabular}{|c|c|c|c|}
\hline 
\textbf{Method} & \textbf{Recall} & \textbf{Precision} & \textbf{Hmean (F1)} \\ 
\hline 
CP3 + Average Laplacian, threshold = 70 & 63.96\% & 36.50\% & \textbf{46.48\%} \\ 
\hline 
CP3 + Average Laplacian, threshold = 65  & 64.15\% & 34.71\% & 45.05\%\\ 
\hline 
CP3 & 65.06\% & 27.75\% & \textbf{38.91\%} \\ 
\hline
Average Laplacian threshold = 65  & 69.97\% & 15.51\% & 25.39\% \\ 
\hline  
CP2 & 63.78\% & 12.74\% & 21.23\% \\ 
\hline 
CP4 & 69.79\% & 9.22\% & 16.29\% \\ 
\hline 
CP1 &\textbf{ 71.71\%} & 6.90\% & 12.68\% \\ 
\hline 
\end{tabular} 
\caption{Performance of our experiments}\label{tab:performanceOur} 
\end{table}

The original approach (CP1) reach the highest recall possible but there was too many false positives its 