
\graphicspath{ {1chapterStateOfArt/image/} }
\chapter{State-of-Art} \label{State-of-Art}
\section{Background}

To fully understand the value of text detection and recognition approaches, this section provides information about the problems, application and challenges.
\subsection{Text in images}
Text in images can be divided into 2 classes: scene text and  born-digital text. Scene text refers to text which is captured in its environment such as sign, advertising, clothing. Born-digital text include text in born-digital images or graphically added into an images which can be found on captions, subtitles and notation in video and born-digital images on webs and email \cite{Karatzas.2011.ICDAR}.
\subsection{Application}
\par
Text in images and video contains valuable information. Text appearing in images and video can provide useful semantic information and become a useful characteristic for many content-based image and video analysis tasks such as content-based image search, multimedia retrieval, visual input and access, and industrial automation.

\begin{itemize}
\item{\textbf{Multimedia retrieval:}}

Text in web images and videos is usually relevant to its content. Graphically added captions and captured scene text usually give information about the situation of event such as location, people. Text recognition and keywords extraction in these resources improves multimedia retrieval. 
\item{\textbf{Visual input and access:}}

With the spread of imaging devices such as digital cameras, cell phones, tablets as well as the improvement of digital processors, a mobile visual input application can be realized. A portable mobile device can be use to digitize documents or automatically input name cards, bank cards, whiteboards \cite{}. As the input become automatically, user experience and efficiency is improved. 

As signs, banner, advertise, product labels carry significant information, automatic text recognition and translation can help people overcome language barriers or support visually impaired in dally life. 

\item{\textbf{Industrial automation:}}

Text recognition on packages, letters, containers, houses, signs and maps relates to industrial automation. A mail sorting system will benefit addresses recognition. Logistics efficiency will be improved by automatic identification of container numbers \cite{39}.

\end{itemize}

\subsection{Challenges}
\begin{center} \label{Chalenges}
\begin{tabular}{|l|l|}
\hline 
\textbf{Category} &\textbf{Challenges} \\ 
\hline 
Environment &Uneven illumination \\ 
	\cline{2-2} 
 	&Scene complexity \\ 
\hline 
Acquisition &Blurring/degradation \\ 
	\cline{2-2} 
	 &Perspective distortion \\ 
\hline 
Text content &Aspect ratio variation \\ 
	\cline{2-2} 
 	&Variation of orientation and curved text \\ 
	\cline{2-2}  
	 &Variation of fonts \\ 
	\cline{2-2} 
 	&Multilingual\\ 
\hline 
\end{tabular} 
\end{center}
\section{Approaches}
Text analysis and recognition includes several sub-problems such as text detection, isolated character recognition, word recognition. They are researched individually (\cite{Campos.2010.CVPR} \cite{Chen.2004.CVPR} \cite{Liu.2006.CRA} \cite{Epshtein.2010.CVPR} \cite{xucheng.2013.pami}) or jointly \cite{Neumann12}. In these problem, the text detection modules is the most important part since it is shown to be critically affect the performance of text in image retrieval algorithms \cite{Epshtein.2010.CVPR}. Although many approaches have been proposed, text detection in scene images (different from digital born one such as embedding text in images) is an open and challenging problem which has been receiving attentions. This is a difficult task due to high variation of scene text such as luminance, contrast, blur, distortion as well as variation of font type and size. Competitions has been held in order to evaluate state-of-art (Text Location Competition at ICDAR 2003, ICDAR 2005, ICDAR 2008 and ICDAR 2013). The leading approach of Task 2.1 (Text Localization in scene images) in ICDAR 2013 obtains a recall of 66.45\% and precision of 88.47\% \cite{ICDAR.2013} which poses significant challenges to state-of-the-art methods today. Related works can be divided into 3 catalogs: texture-based, connected-components and hybrids methods. 
\fxnote{focused text and incidental text}
\par
Texture-based methods \cite{Chen.2004.CVPR} use a sliding windows to look for all possible texts in the image. It bases on hypotheses that text regions in images have distinct textural properties from non-text regions (gradient distribution, texture and structure) that can be identified with a learning machine technique. This approach may become costly in computation because they require calculation of features which describe texts properties of all possible sliding windows at different scale. These approach are also be limited by the learning data base which the learning machine uses. \fxnote{add more paper of this type}
\par
The connected-components (CCs) methods \cite{Epshtein.2010.CVPR} \cite{xucheng.2013.pami} group pixels, which have similar properties such as color, gray level or geometrical arrangement of edges, into connected regions. Detecting texts regardless image properties such as scales, orientation and font type is the advantage of this approach. It also provide a segmentation that can be useful in the OCR step .In the other hand, it might produce high amount of false positives. The CCs obtained may be filtered using texture properties to remove CCs that cannot be characters before grouping into words to reduce false positives rate.
\par
The hybrid methods combine both approaches. Pan et al. \cite{Pan2009} uses HOG features and a Waldboost cascade classifier to generate a text confidence map, based on which connected-components extraction is done by a local binarization. Liu et al \cite{Liu.2006.CRA}, performs on color image, is also a hybrid approach since it use an edge on 3 channel to separate connected components. These candidates will be verified using Harr wavelet transform as texture characterization.
\par
A typical text retrieval process includes 3 steps:
\begin{itemize}\item
Character retrieval: First, Text candidates must be highlighted and distinct from background. These candidate obtained by segmentation or by a characterization process, depends on the approach used (texture or CCs).
\item
Local classification: These candidates may be filtered out to remove non-text regions.
\item
Word grouping: Finally, character candidates will be grouped in to complete words. 
\end{itemize}
\par 
We aim to make a reliable and fast text detectors, which can run on real time application such as detecting text in video. Many approaches \fxnote{cite} tried to detect all the texts candidates as possible then use a machine learning to remove the false positive before continue. This seams to be a redundant as the final purpose of text detection is to pass them into an OCR for recognition. This OCR will surely capable of verify if a candidate is truly a text.
\paragraph{To be continued...}
\fxnote{authors use morphology}
